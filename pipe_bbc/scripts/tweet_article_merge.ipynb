{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make df of articles to analyze. Is just a formatted copy of the scraped articles as we can't glean any\n",
    "# from twitter outlinks as website doesn't allow it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bbc_articles_df', 'rb') as f:\n",
    "    bbc_scrape_articles=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bbc_scrape_articles.drop_duplicates(subset='headline', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_scrape_articles.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_scrape_articles.rename(columns={'text':'artText', 'URL':'expURL'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bbc_articles_analysis', 'wb') as f:\n",
    "    pickle.dump(bbc_scrape_articles, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make df linking articles to tweets (import of colab created df which used similarity of tweets to article lead to link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/import_data/bbc_tw_art_similar', 'rb') as f:\n",
    "    bbc_tw_art_similar=pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_tw_art_similar.drop(['headline_list', 'date_y', 'same_tweet?', 'text_list', 'tweet_summary', 'URL_list'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_tw_art_similar.rename(columns={'date_x':'date', 'text':'artText', 'Text':'tweetText', 'Replies':'replies', 'Retweets':'retweets', 'Likes':'likes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bbc clean tweets was created in colab, combining world and uk dataframes\n",
    "bbc_tweets = pd.read_csv('../data/import_data/all_bbc_tweets.csv', converters={\"Outlinks\": lambda x: x.strip(\"[]\").replace(\"'\",\"\").split(\", \")}, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_cleaner(df):\n",
    "    t_url_list=df['URL_list'].tolist()\n",
    "    new_list=[]\n",
    "    for l in t_url_list:\n",
    "        try:\n",
    "            li = l[2:-2]\n",
    "            li = li.split(', ')\n",
    "        except:\n",
    "            li=['blank']\n",
    "        new_list.append(li)\n",
    "    new_list_format=[]\n",
    "    for n in new_list:\n",
    "        row_list=[]\n",
    "        for nn in n:\n",
    "            nn=nn.strip('\"')\n",
    "            nn=nn.strip(\"'\")\n",
    "            row_list.append(nn)\n",
    "        new_list_format.append(row_list)\n",
    "    df['URL_list'] = new_list_format  \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_tweets=tweet_cleaner(bbc_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_tweets=bbc_tweets.explode('URL_list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbc_tweets.rename(columns={'Text': 'tweetText','URL_list': 'shortURL', 'Replies':'replies', 'Retweets': 'retweets', 'Likes':'likes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe of all tweets, with article if found\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_article_analysis=pd.concat([bbc_tw_art_similar, bbc_tweets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_article_analysis.drop_duplicates('tweetText', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_article_analysis.drop('shortURL', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_article_analysis.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tw in ['replies', 'retweets', 'likes']:\n",
    "    twitter_article_analysis[tw]=twitter_article_analysis[tw].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/bbc_twitter_articles_analysis', 'wb') as f:\n",
    "    pickle.dump(twitter_article_analysis, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
